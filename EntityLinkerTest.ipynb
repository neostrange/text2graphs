{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!doctype html>\n",
      "<html lang=en>\n",
      "  <head>\n",
      "    <title>KeyError: 'document'\n",
      " // Werkzeug Debugger</title>\n",
      "    <link rel=\"stylesheet\" href=\"?__debugger__=yes&amp;cmd=resource&amp;f=style.css\">\n",
      "    <link rel=\"shortcut icon\"\n",
      "        href=\"?__debugger__=yes&amp;cmd=resource&amp;f=console.png\">\n",
      "    <script src=\"?__debugger__=yes&amp;cmd=resource&amp;f=debugger.js\"></script>\n",
      "    <script>\n",
      "      var CONSOLE_MODE = false,\n",
      "          EVALEX = true,\n",
      "          EVALEX_TRUSTED = false,\n",
      "          SECRET = \"8Dj7WqcH86kJnqhNJx2T\";\n",
      "    </script>\n",
      "  </head>\n",
      "  <body style=\"background-color: #fff\">\n",
      "    <div class=\"debugger\">\n",
      "<h1>KeyError</h1>\n",
      "<div class=\"detail\">\n",
      "  <p class=\"errormsg\">KeyError: &#39;document&#39;\n",
      "</p>\n",
      "</div>\n",
      "<h2 class=\"traceback\">Traceback <em>(most recent call last)</em></h2>\n",
      "<div class=\"traceback\">\n",
      "  <h3></h3>\n",
      "  <ul><li><div class=\"frame\" id=\"frame-139941515322752\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/flask/app.py\"</cite>,\n",
      "      line <em class=\"line\">2095</em>,\n",
      "      in <code class=\"function\">__call__</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">    </span>def __call__(self, environ: dict, start_response: t.Callable) -&gt; t.Any:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>&#34;&#34;&#34;The WSGI server calls the Flask application object as the</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>WSGI application. This calls :meth:`wsgi_app`, which can be</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>wrapped to apply middleware.</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">        </span>return self.wsgi_app(environ, start_response)</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515322640\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/flask/app.py\"</cite>,\n",
      "      line <em class=\"line\">2080</em>,\n",
      "      in <code class=\"function\">wsgi_app</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">            </span>try:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">                </span>ctx.push()</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">                </span>response = self.full_dispatch_request()</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>except Exception as e:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">                </span>error = e</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">                </span>response = self.handle_exception(e)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">            </span>except:  # noqa: B001</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">                </span>error = sys.exc_info()[1]</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">                </span>raise</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">            </span>return response(environ, start_response)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>finally:</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515322976\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/flask/app.py\"</cite>,\n",
      "      line <em class=\"line\">2077</em>,\n",
      "      in <code class=\"function\">wsgi_app</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">        </span>ctx = self.request_context(environ)</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>error: t.Optional[BaseException] = None</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>try:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>try:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">                </span>ctx.push()</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">                </span>response = self.full_dispatch_request()</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">            </span>except Exception as e:</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">                </span>error = e</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">                </span>response = self.handle_exception(e)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">            </span>except:  # noqa: B001</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">                </span>error = sys.exc_info()[1]</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515322304\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/flask/app.py\"</cite>,\n",
      "      line <em class=\"line\">1525</em>,\n",
      "      in <code class=\"function\">full_dispatch_request</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">            </span>request_started.send(self)</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>rv = self.preprocess_request()</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>if rv is None:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">                </span>rv = self.dispatch_request()</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>except Exception as e:</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">            </span>rv = self.handle_user_exception(e)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>return self.finalize_request(rv)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">    </span>def finalize_request(</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>self,</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>rv: t.Union[ResponseReturnValue, HTTPException],</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515322192\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/flask/app.py\"</cite>,\n",
      "      line <em class=\"line\">1523</em>,\n",
      "      in <code class=\"function\">full_dispatch_request</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">        </span>self.try_trigger_before_first_request_functions()</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>try:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>request_started.send(self)</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>rv = self.preprocess_request()</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>if rv is None:</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">                </span>rv = self.dispatch_request()</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>except Exception as e:</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">            </span>rv = self.handle_user_exception(e)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>return self.finalize_request(rv)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">    </span>def finalize_request(</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515322416\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/flask/app.py\"</cite>,\n",
      "      line <em class=\"line\">1509</em>,\n",
      "      in <code class=\"function\">dispatch_request</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">            </span>getattr(rule, &#34;provide_automatic_options&#34;, False)</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>and req.method == &#34;OPTIONS&#34;</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>):</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>return self.make_default_options_response()</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span># otherwise dispatch to the handler for that endpoint</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">        </span>return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">    </span>def full_dispatch_request(self) -&gt; Response:</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>&#34;&#34;&#34;Dispatches the request and on top of that performs request</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>pre and postprocessing as well as HTTP exception catching and</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>error handling.</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515322528\">\n",
      "  <h4>File <cite class=\"filename\">\"/app/allennlp_demo/common/http.py\"</cite>,\n",
      "      line <em class=\"line\">215</em>,\n",
      "      in <code class=\"function\">predict_handler</code></h4>\n",
      "  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>@self.app.route(&#34;/predict&#34;, methods=[&#34;POST&#34;])</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>def predict_handler():</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">            </span>if no_cache(request):</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">                </span>return jsonify(self.predict(request.get_json()))</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">            </span>return jsonify(with_cache_hit_response_headers(self.predict_with_cache, request.data))</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>@self.app.route(&#34;/interpret/&lt;string:interpreter_id&gt;&#34;, methods=[&#34;POST&#34;])</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>def interpet_handler(interpreter_id: str):</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">            </span>if no_cache(request):</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">                </span>return jsonify(self.interpret(interpreter_id, request.get_json()))</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515322864\">\n",
      "  <h4>File <cite class=\"filename\">\"/app/allennlp_demo/common/http.py\"</cite>,\n",
      "      line <em class=\"line\">40</em>,\n",
      "      in <code class=\"function\">with_cache_hit_response_headers</code></h4>\n",
      "  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">    </span>The provided function must be memoized using the functools.lru_cache decorator.</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">    </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">    </span># This allows us to determine if the response we&#39;re serving was cached. It&#39;s safe to</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">    </span># do because we use a single-threaded server.</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">    </span>pre_hits = fn.cache_info().hits  # type: ignore</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">    </span>r = fn(*args)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">    </span># If it was a cache hit add a HTTP header to the response</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">    </span>if fn.cache_info().hits - pre_hits == 1:  # type: ignore</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>@after_this_request</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515323088\">\n",
      "  <h4>File <cite class=\"filename\">\"/app/allennlp_demo/common/http.py\"</cite>,\n",
      "      line <em class=\"line\">100</em>,\n",
      "      in <code class=\"function\">predict_with_cache</code></h4>\n",
      "  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\">        </span># be sure that the caches are specific to the instance, and not the class,</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span># i.e. every instance will have its own set of caches.</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>@lru_cache(maxsize=1024)</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>def predict_with_cache(inputs: str) -&gt; JsonDict:</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">            </span>return self.predict(json.loads(inputs))</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>@lru_cache(maxsize=1024)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>def interpret_with_cache(interpreter_id: str, inputs: str) -&gt; JsonDict:</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">            </span>return self.interpret(interpreter_id, json.loads(inputs))</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515323200\">\n",
      "  <h4>File <cite class=\"filename\">\"/app/allennlp_demo/common/http.py\"</cite>,\n",
      "      line <em class=\"line\">156</em>,\n",
      "      in <code class=\"function\">predict</code></h4>\n",
      "  <div class=\"source \"><pre class=\"line before\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">    </span>def predict(self, inputs: JsonDict) -&gt; JsonDict:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>Returns predictions.</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">        </span>return self.predictor.predict_json(inputs)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">    </span>def interpret(self, interpreter_id: str, inputs: JsonDict) -&gt; JsonDict:</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>Interprets the output of a predictor and assigns sailency scores to each, as to find</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>inputs that would change the model&#39;s prediction some desired manner.</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515323312\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/allennlp/predictors/predictor.py\"</cite>,\n",
      "      line <em class=\"line\">54</em>,\n",
      "      in <code class=\"function\">predict_json</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">        </span>you can override this function to output them differently.</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>return json.dumps(outputs) + &#34;\\n&#34;</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">    </span>def predict_json(self, inputs: JsonDict) -&gt; JsonDict:</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">        </span>instance = self._json_to_instance(inputs)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>return self.predict_instance(instance)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\"></span> </pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">    </span>def json_to_labeled_instances(self, inputs: JsonDict) -&gt; List[Instance]:</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>Converts incoming json to a [`Instance`](../data/instance.md),</pre></div>\n",
      "</div>\n",
      "\n",
      "<li><div class=\"frame\" id=\"frame-139941515323424\">\n",
      "  <h4>File <cite class=\"filename\">\"/usr/local/lib/python3.8/site-packages/allennlp_models/coref/predictors/coref.py\"</cite>,\n",
      "      line <em class=\"line\">201</em>,\n",
      "      in <code class=\"function\">_json_to_instance</code></h4>\n",
      "  <div class=\"source library\"><pre class=\"line before\"><span class=\"ws\">    </span>@overrides</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">    </span>def _json_to_instance(self, json_dict: JsonDict) -&gt; Instance:</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>Expects JSON that looks like `{&#34;document&#34;: &#34;string of document text&#34;}`</pre>\n",
      "<pre class=\"line before\"><span class=\"ws\">        </span>&#34;&#34;&#34;</pre>\n",
      "<pre class=\"line current\"><span class=\"ws\">        </span>document = json_dict[&#34;document&#34;]</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>spacy_document = self._spacy(document)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>sentences = [[token.text for token in sentence] for sentence in spacy_document.sents]</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>instance = self._dataset_reader.text_to_instance(sentences)</pre>\n",
      "<pre class=\"line after\"><span class=\"ws\">        </span>return instance</pre></div>\n",
      "</div>\n",
      "</ul>\n",
      "  <blockquote>KeyError: &#39;document&#39;\n",
      "</blockquote>\n",
      "</div>\n",
      "\n",
      "<div class=\"plain\">\n",
      "    <p>\n",
      "      This is the Copy/Paste friendly version of the traceback.\n",
      "    </p>\n",
      "    <textarea cols=\"50\" rows=\"10\" name=\"code\" readonly>Traceback (most recent call last):\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/flask/app.py&#34;, line 2095, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/flask/app.py&#34;, line 2080, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/flask/app.py&#34;, line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/flask/app.py&#34;, line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/flask/app.py&#34;, line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/flask/app.py&#34;, line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File &#34;/app/allennlp_demo/common/http.py&#34;, line 215, in predict_handler\n",
      "    return jsonify(with_cache_hit_response_headers(self.predict_with_cache, request.data))\n",
      "  File &#34;/app/allennlp_demo/common/http.py&#34;, line 40, in with_cache_hit_response_headers\n",
      "    r = fn(*args)\n",
      "  File &#34;/app/allennlp_demo/common/http.py&#34;, line 100, in predict_with_cache\n",
      "    return self.predict(json.loads(inputs))\n",
      "  File &#34;/app/allennlp_demo/common/http.py&#34;, line 156, in predict\n",
      "    return self.predictor.predict_json(inputs)\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/allennlp/predictors/predictor.py&#34;, line 54, in predict_json\n",
      "    instance = self._json_to_instance(inputs)\n",
      "  File &#34;/usr/local/lib/python3.8/site-packages/allennlp_models/coref/predictors/coref.py&#34;, line 201, in _json_to_instance\n",
      "    document = json_dict[&#34;document&#34;]\n",
      "KeyError: &#39;document&#39;\n",
      "</textarea>\n",
      "</div>\n",
      "<div class=\"explanation\">\n",
      "  The debugger caught an exception in your WSGI application.  You can now\n",
      "  look at the traceback which led to the error.  <span class=\"nojavascript\">\n",
      "  If you enable JavaScript you can also use additional features such as code\n",
      "  execution (if the evalex feature is enabled), automatic pasting of the\n",
      "  exceptions and much more.</span>\n",
      "</div>\n",
      "      <div class=\"footer\">\n",
      "        Brought to you by <strong class=\"arthur\">DON'T PANIC</strong>, your\n",
      "        friendly Werkzeug powered traceback interpreter.\n",
      "      </div>\n",
      "    </div>\n",
      "\n",
      "    <div class=\"pin-prompt\">\n",
      "      <div class=\"inner\">\n",
      "        <h3>Console Locked</h3>\n",
      "        <p>\n",
      "          The console is locked and needs to be unlocked by entering the PIN.\n",
      "          You can find the PIN printed out on the standard output of your\n",
      "          shell that runs the server.\n",
      "        <form>\n",
      "          <p>PIN:\n",
      "            <input type=text name=pin size=14>\n",
      "            <input type=submit name=btn value=\"Confirm Pin\">\n",
      "        </form>\n",
      "      </div>\n",
      "    </div>\n",
      "  </body>\n",
      "</html>\n",
      "\n",
      "<!--\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 2095, in __call__\n",
      "    return self.wsgi_app(environ, start_response)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 2080, in wsgi_app\n",
      "    response = self.handle_exception(e)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 2077, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 1525, in full_dispatch_request\n",
      "    rv = self.handle_user_exception(e)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 1523, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/usr/local/lib/python3.8/site-packages/flask/app.py\", line 1509, in dispatch_request\n",
      "    return self.ensure_sync(self.view_functions[rule.endpoint])(**req.view_args)\n",
      "  File \"/app/allennlp_demo/common/http.py\", line 215, in predict_handler\n",
      "    return jsonify(with_cache_hit_response_headers(self.predict_with_cache, request.data))\n",
      "  File \"/app/allennlp_demo/common/http.py\", line 40, in with_cache_hit_response_headers\n",
      "    r = fn(*args)\n",
      "  File \"/app/allennlp_demo/common/http.py\", line 100, in predict_with_cache\n",
      "    return self.predict(json.loads(inputs))\n",
      "  File \"/app/allennlp_demo/common/http.py\", line 156, in predict\n",
      "    return self.predictor.predict_json(inputs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/allennlp/predictors/predictor.py\", line 54, in predict_json\n",
      "    instance = self._json_to_instance(inputs)\n",
      "  File \"/usr/local/lib/python3.8/site-packages/allennlp_models/coref/predictors/coref.py\", line 201, in _json_to_instance\n",
      "    document = json_dict[\"document\"]\n",
      "KeyError: 'document'\n",
      "\n",
      "\n",
      "-->\n",
      "\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m doc \u001b[39m=\u001b[39m nlp(\u001b[39m\"\u001b[39m\u001b[39mJapan began the defence of their title with a lucky 2-1 win against Syria in a championship match on Friday.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m#for span in doc.ents:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m  \u001b[39m#   print((span.text, span.kb_id_, span.label_, span._.description, span._.score))\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m#print(doc.text)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m result \u001b[39m=\u001b[39m callAllenNlpApi(\u001b[39m\"\u001b[39;49m\u001b[39mcoreference-resolution\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mthe quick brown fox jumps over the lazy dog.\u001b[39;49m\u001b[39m\"\u001b[39;49m )\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/environments/text2graphs/text2graphs/util/RestCaller.py:17\u001b[0m, in \u001b[0;36mcallAllenNlpApi\u001b[0;34m(apiName, string)\u001b[0m\n\u001b[1;32m     13\u001b[0m r \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mpost(URL, headers\u001b[39m=\u001b[39mPARAMS, data\u001b[39m=\u001b[39mjson\u001b[39m.\u001b[39mdumps(payload))\n\u001b[1;32m     15\u001b[0m \u001b[39mprint\u001b[39m(r\u001b[39m.\u001b[39mtext)\n\u001b[0;32m---> 17\u001b[0m \u001b[39mreturn\u001b[39;00m json\u001b[39m.\u001b[39;49mloads(r\u001b[39m.\u001b[39;49mtext)\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    352\u001b[0m     \u001b[39mdel\u001b[39;00m kw[\u001b[39m'\u001b[39m\u001b[39mencoding\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    354\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    355\u001b[0m         parse_int \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m parse_float \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m\n\u001b[1;32m    356\u001b[0m         parse_constant \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m object_pairs_hook \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m kw):\n\u001b[0;32m--> 357\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_decoder\u001b[39m.\u001b[39;49mdecode(s)\n\u001b[1;32m    358\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    359\u001b[0m     \u001b[39mcls\u001b[39m \u001b[39m=\u001b[39m JSONDecoder\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecode\u001b[39m(\u001b[39mself\u001b[39m, s, _w\u001b[39m=\u001b[39mWHITESPACE\u001b[39m.\u001b[39mmatch):\n\u001b[1;32m    333\u001b[0m     \u001b[39m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[39m    containing a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mraw_decode(s, idx\u001b[39m=\u001b[39;49m_w(s, \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mend())\n\u001b[1;32m    338\u001b[0m     end \u001b[39m=\u001b[39m _w(s, end)\u001b[39m.\u001b[39mend()\n\u001b[1;32m    339\u001b[0m     \u001b[39mif\u001b[39;00m end \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(s):\n",
      "File \u001b[0;32m/usr/lib/python3.8/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    353\u001b[0m     obj, end \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscan_once(s, idx)\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[39mraise\u001b[39;00m JSONDecodeError(\u001b[39m\"\u001b[39m\u001b[39mExpecting value\u001b[39m\u001b[39m\"\u001b[39m, s, err\u001b[39m.\u001b[39mvalue) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    356\u001b[0m \u001b[39mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from util.RestCaller import callAllenNlpApi\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "#nlp.add_pipe('opentapioca')\n",
    "doc = nlp(\"Japan began the defence of their title with a lucky 2-1 win against Syria in a championship match on Friday.\")\n",
    "#for span in doc.ents:\n",
    " #   print((span.text, span.kb_id_, span.label_, span._.description, span._.score))\n",
    "\n",
    "#print(doc.text)\n",
    "\n",
    "result = callAllenNlpApi(\"coreference-resolution\", \"the quick brown fox jumps over the lazy dog.\" )\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clusters:  []\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from util.CallAllenNlpCoref import callAllenNlpCoref\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "#nlp.add_pipe('opentapioca')\n",
    "#doc = nlp(\"john bought a new fast 4-wheel car. The car became the slow one in a year and he is sad.  He will buy a new car in next year.  \")\n",
    "doc = nlp(\"john bought a new fast 4-wheel car.\")\n",
    "#for span in doc.ents:\n",
    " #   print((span.text, span.kb_id_, span.label_, span._.description, span._.score))\n",
    "\n",
    "#print(doc.text)\n",
    "\n",
    "result = callAllenNlpCoref(\"coreference-resolution\", doc.text )\n",
    "\n",
    "print(\"clusters: \" , result[\"clusters\"])\n",
    "\n",
    "for cluster in result[\"clusters\"]:\n",
    "    #print(\"cluster: \", cluster)\n",
    "    i = 0\n",
    "    reference = \"\"\n",
    "    for span in cluster:\n",
    "        if i == 0:\n",
    "            i+=1\n",
    "            # the first span will be the reference point for all other coreferences link\n",
    "            reference = span[0]\n",
    "            continue\n",
    "        mention = {'from_index': span[0], 'to_index': reference}\n",
    "        print (mention)\n",
    "        #print (chunk)\n",
    "\n",
    "    #mention = {'from_index': cluster.mentions[-1].start_char, 'to_index': cluster.mentions[0].start_char}\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_trf' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'referent': {'start_index': 10, 'end_index': 11, 'text': He}, 'antecedent': {'start_index': 0, 'end_index': 1, 'text': john}}]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 89>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=103'>104</a>\u001b[0m     coref\u001b[39m.\u001b[39mappend(mention)\n\u001b[1;32m    <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=105'>106</a>\u001b[0m \u001b[39mprint\u001b[39m(coref)\n\u001b[0;32m--> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=107'>108</a>\u001b[0m \u001b[39mprint\u001b[39m(store_coref_mentions(doc, coref))\n",
      "\u001b[1;32m/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb Cell 3\u001b[0m in \u001b[0;36mstore_coref_mentions\u001b[0;34m(doc, mentions)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=36'>37</a>\u001b[0m query \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmatch (x:TagOccurrence \u001b[39m\u001b[39m{\u001b[39m\u001b[39mtok_index_doc:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(index) \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m})-[:HAS_TOKEN]-()-[:CONTAINS_SENTENCE]-(:AnnotatedText \u001b[39m\u001b[39m{\u001b[39m\u001b[39mid:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m+\u001b[39m\u001b[39mstr\u001b[39m(doc\u001b[39m.\u001b[39m_\u001b[39m.\u001b[39mtext_id)\u001b[39m+\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m}) return x\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=37'>38</a>\u001b[0m token_node\u001b[39m=\u001b[39m graph\u001b[39m.\u001b[39mevaluate(query)\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=38'>39</a>\u001b[0m token_mention_rel \u001b[39m=\u001b[39m PARTICIPATES_IN(token_node,corefMention_node)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mif\u001b[39;00m sg \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/neo/environments/text2graphs/text2graphs/EntityLinkerTest.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=40'>41</a>\u001b[0m     sg \u001b[39m=\u001b[39m token_mention_rel\n",
      "File \u001b[0;32m~/environments/text2graphs/venv/lib/python3.8/site-packages/py2neo/data.py:847\u001b[0m, in \u001b[0;36mRelationship.__init__\u001b[0;34m(self, *nodes, **properties)\u001b[0m\n\u001b[1;32m    845\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mHyperedges not supported\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 847\u001b[0m Entity\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, (n[\u001b[39m0\u001b[39;49m], \u001b[39mself\u001b[39;49m, n[\u001b[39m1\u001b[39;49m]), properties)\n",
      "File \u001b[0;32m~/environments/text2graphs/venv/lib/python3.8/site-packages/py2neo/data.py:553\u001b[0m, in \u001b[0;36mEntity.__init__\u001b[0;34m(self, iterable, properties)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, iterable, properties):\n\u001b[0;32m--> 553\u001b[0m     Walkable\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39mself\u001b[39;49m, iterable)\n\u001b[1;32m    554\u001b[0m     PropertyDict\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, properties)\n\u001b[1;32m    555\u001b[0m     uuid \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(uuid4())\n",
      "File \u001b[0;32m~/environments/text2graphs/venv/lib/python3.8/site-packages/py2neo/data.py:453\u001b[0m, in \u001b[0;36mWalkable.__init__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    451\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__sequence[\u001b[39m0\u001b[39m::\u001b[39m2\u001b[39m]\n\u001b[1;32m    452\u001b[0m \u001b[39mfor\u001b[39;00m node \u001b[39min\u001b[39;00m nodes:\n\u001b[0;32m--> 453\u001b[0m     _ \u001b[39m=\u001b[39m node\u001b[39m.\u001b[39;49mlabels  \u001b[39m# ensure not stale\u001b[39;00m\n\u001b[1;32m    454\u001b[0m Subgraph\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, nodes, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m__sequence[\u001b[39m1\u001b[39m::\u001b[39m2\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'labels'"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from py2neo import Graph\n",
    "from py2neo import *\n",
    "from util.CallAllenNlpCoref import callAllenNlpCoref\n",
    "from spacy.tokens import Doc, Token, Span\n",
    "\n",
    "\n",
    "\n",
    "def store_coref_mentions(doc, mentions):\n",
    "    uri = 'bolt://10.1.54.74:7687'\n",
    "    username = 'neo4j'\n",
    "    password = 'neo123'\n",
    "    graph = Graph(uri, auth=(username, password))\n",
    "\n",
    "    # create the referrant span , attaches it with the tagOccurrences\n",
    "    # identify the namedEntity that belongs to the antecedent\n",
    "    # \n",
    "\n",
    "    sg=\"\"\n",
    "    PARTICIPANT = Relationship.type(\"PARTICIPANT\")\n",
    "    PARTICIPATES_IN = Relationship.type(\"PARTICIPATES_IN\")\n",
    "    MENTIONS = Relationship.type(\"MENTIONS\")\n",
    "\n",
    "    for mention in mentions:\n",
    "        \n",
    "        start_index = mention['referent']['start_index']\n",
    "        end_index = mention['referent']['end_index']\n",
    "        start_index_antecedent = mention['antecedent']['end_index']\n",
    "        end_index_antecedent = mention['antecedent']['end_index']\n",
    "\n",
    "        # create a corefMention node\n",
    "        corefMention_node = Node(\"CorefMention\", text=mention['referent']['text'], startIndex=start_index, endIndex=end_index)\n",
    "        \n",
    "        # connect the corefMention node with all the participating tagOccurrences\n",
    "        index_range = range(start_index, end_index)\n",
    "        for index in index_range:\n",
    "            query = \"match (x:TagOccurrence {tok_index_doc:\" + str(index) + \"})-[:HAS_TOKEN]-()-[:CONTAINS_SENTENCE]-(:AnnotatedText {id:\"+str(doc._.text_id)+\"}) return x\"\n",
    "            token_node= graph.evaluate(query)\n",
    "            token_mention_rel = PARTICIPATES_IN(token_node,corefMention_node)\n",
    "            if sg == \"\":\n",
    "                sg = token_mention_rel\n",
    "            else:\n",
    "                sg = sg | token_mention_rel\n",
    "        \n",
    "        # connect the corefMention node with the antecdent namedEntity. \n",
    "        np_query = \"\"\"MATCH (document:AnnotatedText {id:\"\"\"+str(doc._.text_id)+\"\"\"})-[*2]->(np:TagOccurrence)-[:PARTICIPATES_IN]->(end:NamedEntity) \n",
    "            WHERE np.index = \"\"\" +start_index_antecedent + \"\"\"\n",
    "            RETURN np\"\"\"\n",
    "        np_node = graph.evaluate(np_query)\n",
    "        if np_node is None:\n",
    "            try:\n",
    "                graph.create(sg)\n",
    "            except BaseException as err:\n",
    "                print(f\"Unexpected {err=}, {type(err)=}\")\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        coref_mention_np_rel = MENTIONS(corefMention_node,np_node)\n",
    "        \n",
    "        sg = sg | coref_mention_np_rel\n",
    "        \n",
    "        try:\n",
    "            graph.create(sg)\n",
    "        except BaseException as err:\n",
    "            print(f\"Unexpected {err=}, {type(err)=}\") \n",
    "    return sg\n",
    "\n",
    "if not Doc.has_extension(\"text_id\"):\n",
    "    Doc.set_extension(\"text_id\", default=1)\n",
    "\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "#nlp.add_pipe('opentapioca')\n",
    "#doc = nlp(\"john bought a new fast 4-wheel car. The car became the slow one in a year and he is sad.  He will buy a new car in next year.  \")\n",
    "doc = nlp(\"john bought a new fast 4-wheel car. He drives the car very fast.\")\n",
    "#for span in doc.ents:\n",
    " #   print((span.text, span.kb_id_, span.label_, span._.description, span._.score))\n",
    "\n",
    "#print(doc.text)\n",
    "\n",
    "result = callAllenNlpCoref(\"coreference-resolution\", doc.text )\n",
    "\n",
    "#print(\"clusters: \" , result[\"clusters\"])\n",
    "# storing the coreference mentions as graph nodes linked with antecedent via mentions edges\n",
    "        # steps\n",
    "        # 1. get the coref-mention and antedent pair\n",
    "coref = []\n",
    "for cluster in result[\"clusters\"]:\n",
    "    i=0\n",
    "    antecedent_span = \"\"\n",
    "    for span_token_indexes in cluster:\n",
    "        if i == 0:\n",
    "            i+=1\n",
    "            # the first span will be the antecedent for all other references\n",
    "            antecedent_span = doc[span_token_indexes[0]:span_token_indexes[-1]+1]\n",
    "            antecedent_node = {'start_index': span_token_indexes[0], 'end_index': span_token_indexes[-1]+1, 'text': antecedent_span}\n",
    "            continue\n",
    "        coref_mention_span = doc[span_token_indexes[0]:span_token_indexes[-1]+1]\n",
    "        coref_mention_node = {'start_index': span_token_indexes[0], 'end_index': span_token_indexes[-1]+1, 'text': coref_mention_span}\n",
    "        #mention = {'from_index': span[-1], 'to_index': antecedent}\n",
    "        #mention = { 'referent': coref_mention_span, 'antecedent': antecedent_span}\n",
    "        mention = { 'referent': coref_mention_node, 'antecedent': antecedent_node}\n",
    "        coref.append(mention)\n",
    "    \n",
    "    print(coref)\n",
    "\n",
    "    print(store_coref_mentions(doc, coref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_trf' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk:  Jim Cramer root:  Cramer root dep:  nsubj head:  remarked\n",
      "chunk:  CNBC's Mad Money root:  Money root dep:  pobj head:  of\n",
      "chunk:  as many as seven million people root:  people root dep:  nsubj head:  lose\n",
      "chunk:  their homes root:  homes root dep:  dobj head:  lose\n",
      "chunk:  bad mortgages root:  mortgages root dep:  pobj head:  from\n",
      "chunk:  Cramer root:  Cramer root dep:  nsubj head:  went\n",
      "chunk:  a tirade root:  tirade root dep:  pobj head:  on\n",
      "chunk:  CNBC's Street Signs root:  Signs root dep:  pobj head:  on\n",
      "chunk:  the \"Fed root:  Fed root dep:  nsubj head:  was\n",
      "chunk:  them root:  them root dep:  nsubj head:  lower\n",
      "chunk:  rates root:  rates root dep:  dobj head:  lower\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank(\"en\")\n",
    "#nlp.add_pipe('opentapioca')\n",
    "#doc = nlp(\"john bought a new fast 4-wheel car. The car became the slow one in a year and he is sad.  He will buy a new car in next year.  \")\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "doc = nlp(\"\"\"Jim Cramer, of CNBC's Mad Money, remarked that as many as seven million people will lose their homes from bad mortgages. Last Friday, Cramer went on a tirade on CNBC's Street Signs, saying that the \"Fed was asleep\" and called for them to lower rates immediately.\"\"\")\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(\"chunk: \", chunk.text, \"root: \", chunk.root.text, \"root dep: \", chunk.root.dep_,\n",
    "            \"head: \", chunk.root.head.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "tree = ET.parse('/home/neo/environments/text2graphs/text2graphs/dataset/76437_Markets_dragged_down_by_credit_crisis.naf')\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NAF'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root.tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nGlobal stock markets fell today, in a mass sell-off stemming from the sub-prime mortgage crisis in the United States. The Dow Jones Industrial Average rebounded late in the day after falling more than 250 points, ending the day down about 31 points. The UK\\'s FTSE-100 index fell 232.90 points to 6038.30, and Japan\\'s Nikkei 225 fell 406.51 points to 16764.09. \\n\\nCentral banks across the world are injecting funds into their banking systems to add liquidity, fearing that many financial firms with subprime ties will be insolvent. Yesterday, the U.S. Federal Reserve transferred US$24 billion to temporary reserves, following the European Central Bank, which authorized a record 83.6 billion addition to its banks, its biggest cash infusion ever. On Friday, the Fed entered into a $38 billion repurchase agreement of mortgage-backed securities, easing stockholder worries. Also on Friday, the Bank of Japan injected 1 trillion into Japan\\'s financial system. \\n\\nThe Federal Reserve met this week, but decided to maintain its target rate of 5.25%, although on Friday the federal funds rate was hovering around 6%, indicating a drop in liquidity. \\n\\nThe volatile week began last Friday with Bear Stearns tumbling as a result from its complete loss of two major hedge funds worth more than $1.5 billion. The hedge funds had been dangerously exposed to the massive sub-prime mortgage failure, and the company announced it was unable to return any money to investors. \\n\\nWashington Mutual, and Countrywide Financial, both very large U.S. home loan lenders, saw shares fall. Countrywide Financial made a statement this week, saying they will be forced to retain a greater proportion of mortgage. American Home Mortgage Investment Corp, another large lender, recently filed for bankruptcy. The U.S. housing market has been declining for more than two years after the Federal Reserve raised interest rates 17 times. Now, lenders are in a quagmire from millions of people who are unable to repay loans after taking adjustable rate mortgages, teaser rates, interest-only mortgages, or piggyback rates. \\n\\nJim Cramer, of CNBC\\'s Mad Money, remarked that as many as seven million people will lose their homes from bad mortgages. Last Friday, Cramer went on a tirade on CNBC\\'s Street Signs, saying that the \"Fed was asleep\" and called for them to lower rates immediately. \\n\\nAsian and European markets have become increasingly entangled in the subprime mortgage crisis in the U.S. Deutsche Bank of Germany lost almost $3.5 billion in share value, forcing the government to organize a bail-out. France\\'s largest bank, BNP Paribas SA, halted withdrawals from three large investment funds which were crippled by sub-prime exposure.\\n\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root[1].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_trf' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4 4\n",
      "5 2 7\n",
      "8 1 9\n",
      "10 8 18\n",
      "19 7 26\n",
      "27 2 29\n",
      "30 7 37\n",
      "38 2 40\n",
      "41 1 42\n",
      "43 6 49\n",
      "50 7 57\n",
      "58 7 65\n",
      "65 1 66\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_trf\")\n",
    "doc=nlp(\"This is a sentence written in english by a native English speaker.\")\n",
    "\n",
    "\n",
    "for tok in doc:\n",
    "    print( tok.idx, len(tok.text), len(tok.text)+tok.idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ". . The biggest U.S. stock market index, the Dow Jones, plunged by more than 416 points by the closing bell on Tuesday, the worst single-day decline since the re-opening of the markets following the September 11th terrorist attacks. The slip followed a 9% sell-off in Chinese markets. Other stock indices, such as the Nasdaq and the S&amp;P 500, dipped by 96 points and 50 points, respectively. It was the 7th largest single-day decline is U.S. history.. Analysts blamed the slide on a number of factors: (1) U.S. and Chinese stock exchanges had powered upward for too long and were due for a significant correction; (2) inflation and the prices of bonds and equities had become too high; (3) the U.S. is headed for an economic recession. Alan Greenspan indicated on Monday that the U.S. economy would not sustain its recent growth, where the Dow Industrials set day-to-day records and the White House signaled on Tuesday that it would revise its estimate of fourth-quarter 2006 GDP growth down to an annual rate of about 2.3 percent from an initial forecast of 3.5 percent and was increasingly nervous that the figure could come in even lower. Around 3 p.m. EST, Reuters reported that the New York Stock Exchange had implemented on-floor tradition restrictions meant to curb the sell off.. The decline also occurred on the day that a plot to assassinate U.S. Vice President Richard Cheney failed in Afghanistan.. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_trf' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  .\n",
      "1  :  .\n",
      "2  :  The biggest U.S. stock market index, the Dow Jones, plunged by more than 416 points by the closing bell on Tuesday, the worst single-day decline since the re-opening of the markets following the September 11th terrorist attacks.\n",
      "47  :  The slip followed a 9% sell-off in Chinese markets.\n",
      "60  :  Other stock indices, such as the Nasdaq and the S&amp;P 500, dipped by 96 points and 50 points, respectively.\n",
      "83  :  It was the 7th largest single-day decline is U.S. history..\n",
      "96  :  Analysts blamed the slide on a number of factors: (1) U.S. and Chinese stock exchanges had powered upward for too long and were due for a significant correction; (2) inflation and the prices of bonds and equities had become too high; (3) the U.S. is headed for an economic recession.\n",
      "156  :  Alan Greenspan indicated on Monday that the U.S. economy would not sustain its recent growth, where the Dow Industrials set day-to-day records and the White House signaled on Tuesday that it would revise its estimate of fourth-quarter 2006 GDP growth down to an annual rate of about 2.3 percent from an initial forecast of 3.5 percent and was increasingly nervous that the figure could come in even lower.\n",
      "232  :  Around 3 p.m. EST, Reuters reported that the New York Stock Exchange had implemented on-floor tradition restrictions meant to curb the sell off..\n",
      "259  :  The decline also occurred on the day that a plot to assassinate U.S. Vice President Richard Cheney failed in Afghanistan..\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "The biggest U.S. stock market index, the Dow Jones, plunged by more than 416 points by the closing bell on Tuesday, the worst single-day decline since the re-opening of the markets following the September 11th terrorist attacks. The slip followed a 9% sell-off in Chinese markets. Other stock indices, such as the Nasdaq and the S&amp;P 500, dipped by 96 points and 50 points, respectively. It was the 7th largest single-day decline is U.S. history.\n",
    "\n",
    "Analysts blamed the slide on a number of factors: (1) U.S. and Chinese stock exchanges had powered upward for too long and were due for a significant correction; (2) inflation and the prices of bonds and equities had become too high; (3) the U.S. is headed for an economic recession. Alan Greenspan indicated on Monday that the U.S. economy would not sustain its recent growth, where the Dow Industrials set day-to-day records and the White House signaled on Tuesday that it would revise its estimate of fourth-quarter 2006 GDP growth down to an annual rate of about 2.3 percent from an initial forecast of 3.5 percent and was increasingly nervous that the figure could come in even lower.\n",
    "Around 3 p.m. EST, Reuters reported that the New York Stock Exchange had implemented on-floor tradition restrictions meant to curb the sell off.\n",
    "\n",
    "The decline also occurred on the day that a plot to assassinate U.S. Vice President Richard Cheney failed in Afghanistan.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#text = text.replace('\\n\\n','. ')\n",
    "\n",
    "text = text.replace('\\n','')\n",
    "\n",
    "print(text)\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_trf\")\n",
    "doc=nlp(text)\n",
    "\n",
    "i=0\n",
    "\n",
    "\n",
    "for sent in doc.sents:\n",
    "    print(sent.start,\" : \", sent.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_trf' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  :  .\n",
      "2  :  The\n",
      "6  :  biggest\n",
      "14  :  U.S.\n",
      "19  :  stock\n",
      "25  :  market\n",
      "32  :  index\n",
      "37  :  ,\n",
      "39  :  the\n",
      "43  :  Dow\n",
      "47  :  Jones\n",
      "52  :  ,\n",
      "54  :  plunged\n",
      "62  :  by\n",
      "65  :  more\n",
      "70  :  than\n",
      "75  :  416\n",
      "79  :  points\n",
      "86  :  by\n",
      "89  :  the\n",
      "93  :  closing\n",
      "101  :  bell\n",
      "106  :  on\n",
      "109  :  Tuesday\n",
      "116  :  ,\n",
      "118  :  the\n",
      "122  :  worst\n",
      "128  :  single\n",
      "134  :  -\n",
      "135  :  day\n",
      "139  :  decline\n",
      "147  :  since\n",
      "153  :  the\n",
      "157  :  re\n",
      "159  :  -\n",
      "160  :  opening\n",
      "168  :  of\n",
      "171  :  the\n",
      "175  :  markets\n",
      "183  :  following\n",
      "193  :  the\n",
      "197  :  September\n",
      "207  :  11th\n",
      "212  :  terrorist\n",
      "222  :  attacks\n",
      "229  :  .\n",
      "231  :  The\n",
      "235  :  slip\n",
      "240  :  followed\n",
      "249  :  a\n",
      "251  :  9\n",
      "252  :  %\n",
      "254  :  sell\n",
      "258  :  -\n",
      "259  :  off\n",
      "263  :  in\n",
      "266  :  Chinese\n",
      "274  :  markets\n",
      "281  :  .\n",
      "283  :  Other\n",
      "289  :  stock\n",
      "295  :  indices\n",
      "302  :  ,\n",
      "304  :  such\n",
      "309  :  as\n",
      "312  :  the\n",
      "316  :  Nasdaq\n",
      "323  :  and\n",
      "327  :  the\n",
      "331  :  S&amp;P\n",
      "339  :  500\n",
      "342  :  ,\n",
      "344  :  dipped\n",
      "351  :  by\n",
      "354  :  96\n",
      "357  :  points\n",
      "364  :  and\n",
      "368  :  50\n",
      "371  :  points\n",
      "377  :  ,\n",
      "379  :  respectively\n",
      "391  :  .\n",
      "393  :  It\n",
      "396  :  was\n",
      "400  :  the\n",
      "404  :  7th\n",
      "408  :  largest\n",
      "416  :  single\n",
      "422  :  -\n",
      "423  :  day\n",
      "427  :  decline\n",
      "435  :  is\n",
      "438  :  U.S.\n",
      "443  :  history\n",
      "450  :  .\n",
      "451  :  \n",
      "\n",
      "\n",
      "453  :  Analysts\n",
      "462  :  blamed\n",
      "469  :  the\n",
      "473  :  slide\n",
      "479  :  on\n",
      "482  :  a\n",
      "484  :  number\n",
      "491  :  of\n",
      "494  :  factors\n",
      "501  :  :\n",
      "503  :  (\n",
      "504  :  1\n",
      "505  :  )\n",
      "507  :  U.S.\n",
      "512  :  and\n",
      "516  :  Chinese\n",
      "524  :  stock\n",
      "530  :  exchanges\n",
      "540  :  had\n",
      "544  :  powered\n",
      "552  :  upward\n",
      "559  :  for\n",
      "563  :  too\n",
      "567  :  long\n",
      "572  :  and\n",
      "576  :  were\n",
      "581  :  due\n",
      "585  :  for\n",
      "589  :  a\n",
      "591  :  significant\n",
      "603  :  correction\n",
      "613  :  ;\n",
      "615  :  (\n",
      "616  :  2\n",
      "617  :  )\n",
      "619  :  inflation\n",
      "629  :  and\n",
      "633  :  the\n",
      "637  :  prices\n",
      "644  :  of\n",
      "647  :  bonds\n",
      "653  :  and\n",
      "657  :  equities\n",
      "666  :  had\n",
      "670  :  become\n",
      "677  :  too\n",
      "681  :  high\n",
      "685  :  ;\n",
      "687  :  (\n",
      "688  :  3\n",
      "689  :  )\n",
      "691  :  the\n",
      "695  :  U.S.\n",
      "700  :  is\n",
      "703  :  headed\n",
      "710  :  for\n",
      "714  :  an\n",
      "717  :  economic\n",
      "726  :  recession\n",
      "735  :  .\n",
      "737  :  Alan\n",
      "742  :  Greenspan\n",
      "752  :  indicated\n",
      "762  :  on\n",
      "765  :  Monday\n",
      "772  :  that\n",
      "777  :  the\n",
      "781  :  U.S.\n",
      "786  :  economy\n",
      "794  :  would\n",
      "800  :  not\n",
      "804  :  sustain\n",
      "812  :  its\n",
      "816  :  recent\n",
      "823  :  growth\n",
      "829  :  ,\n",
      "831  :  where\n",
      "837  :  the\n",
      "841  :  Dow\n",
      "845  :  Industrials\n",
      "857  :  set\n",
      "861  :  day\n",
      "864  :  -\n",
      "865  :  to\n",
      "867  :  -\n",
      "868  :  day\n",
      "872  :  records\n",
      "880  :  and\n",
      "884  :  the\n",
      "888  :  White\n",
      "894  :  House\n",
      "900  :  signaled\n",
      "909  :  on\n",
      "912  :  Tuesday\n",
      "920  :  that\n",
      "925  :  it\n",
      "928  :  would\n",
      "934  :  revise\n",
      "941  :  its\n",
      "945  :  estimate\n",
      "954  :  of\n",
      "957  :  fourth\n",
      "963  :  -\n",
      "964  :  quarter\n",
      "972  :  2006\n",
      "977  :  GDP\n",
      "981  :  growth\n",
      "988  :  down\n",
      "993  :  to\n",
      "996  :  an\n",
      "999  :  annual\n",
      "1006  :  rate\n",
      "1011  :  of\n",
      "1014  :  about\n",
      "1020  :  2.3\n",
      "1024  :  percent\n",
      "1032  :  from\n",
      "1037  :  an\n",
      "1040  :  initial\n",
      "1048  :  forecast\n",
      "1057  :  of\n",
      "1060  :  3.5\n",
      "1064  :  percent\n",
      "1072  :  and\n",
      "1076  :  was\n",
      "1080  :  increasingly\n",
      "1093  :  nervous\n",
      "1101  :  that\n",
      "1106  :  the\n",
      "1110  :  figure\n",
      "1117  :  could\n",
      "1123  :  come\n",
      "1128  :  in\n",
      "1131  :  even\n",
      "1136  :  lower\n",
      "1141  :  .\n",
      "1142  :  \n",
      "\n",
      "\n",
      "1144  :  Around\n",
      "1151  :  3\n",
      "1153  :  p.m.\n",
      "1158  :  EST\n",
      "1161  :  ,\n",
      "1163  :  Reuters\n",
      "1171  :  reported\n",
      "1180  :  that\n",
      "1185  :  the\n",
      "1189  :  New\n",
      "1193  :  York\n",
      "1198  :  Stock\n",
      "1204  :  Exchange\n",
      "1213  :  had\n",
      "1217  :  implemented\n",
      "1229  :  on\n",
      "1231  :  -\n",
      "1232  :  floor\n",
      "1238  :  tradition\n",
      "1248  :  restrictions\n",
      "1261  :  meant\n",
      "1267  :  to\n",
      "1270  :  curb\n",
      "1275  :  the\n",
      "1279  :  sell\n",
      "1284  :  off\n",
      "1287  :  .\n",
      "1288  :  \n",
      "\n",
      "\n",
      "1290  :  The\n",
      "1294  :  decline\n",
      "1302  :  also\n",
      "1307  :  occurred\n",
      "1316  :  on\n",
      "1319  :  the\n",
      "1323  :  day\n",
      "1327  :  that\n",
      "1332  :  a\n",
      "1334  :  plot\n",
      "1339  :  to\n",
      "1342  :  assassinate\n",
      "1354  :  U.S.\n",
      "1359  :  Vice\n",
      "1364  :  President\n",
      "1374  :  Richard\n",
      "1382  :  Cheney\n",
      "1389  :  failed\n",
      "1396  :  in\n",
      "1399  :  Afghanistan\n",
      "1410  :  .\n",
      "1411  :  \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\". The biggest U.S. stock market index, the Dow Jones, plunged by more than 416 points by the closing bell on Tuesday, the worst single-day decline since the re-opening of the markets following the September 11th terrorist attacks. The slip followed a 9% sell-off in Chinese markets. Other stock indices, such as the Nasdaq and the S&amp;P 500, dipped by 96 points and 50 points, respectively. It was the 7th largest single-day decline is U.S. history.\n",
    "\n",
    "Analysts blamed the slide on a number of factors: (1) U.S. and Chinese stock exchanges had powered upward for too long and were due for a significant correction; (2) inflation and the prices of bonds and equities had become too high; (3) the U.S. is headed for an economic recession. Alan Greenspan indicated on Monday that the U.S. economy would not sustain its recent growth, where the Dow Industrials set day-to-day records and the White House signaled on Tuesday that it would revise its estimate of fourth-quarter 2006 GDP growth down to an annual rate of about 2.3 percent from an initial forecast of 3.5 percent and was increasingly nervous that the figure could come in even lower.\n",
    "\n",
    "Around 3 p.m. EST, Reuters reported that the New York Stock Exchange had implemented on-floor tradition restrictions meant to curb the sell off.\n",
    "\n",
    "The decline also occurred on the day that a plot to assassinate U.S. Vice President Richard Cheney failed in Afghanistan.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_trf\")\n",
    "doc=nlp(text)\n",
    "\n",
    "for tok in doc:\n",
    "    print(tok.idx,\" : \", tok.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_trf' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n",
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 :  \n",
      "\n",
      "\n",
      "1 :  The biggest\n",
      "3 :  U.S. stock market index, the\n",
      "9 :  Dow\n",
      "10 :  Jones, plunged by more than 416 points by the closing bell on\n",
      "23 :  Tuesday, the worst single-day decline since the re-opening of the markets following the\n",
      "41 :  September 11th terrorist attacks.\n",
      "46 :  The slip followed a 9% sell-off in\n",
      "56 :  Chinese markets.\n",
      "59 :  Other stock indices, such as the\n",
      "66 :  Nasdaq and the S&amp;P 500, dipped by 96 points and 50 points, respectively.\n",
      "82 :  It was the 7th largest single-day decline is\n",
      "92 :  U.S. history.\n",
      "\n",
      "\n",
      "96 :  Analysts blamed the slide on a number of factors: (1)\n",
      "109 :  U.S. and\n",
      "111 :  Chinese stock exchanges had powered upward for too long and were due for a significant correction; (2) inflation and the prices of bonds and equities had become too high; (3) the\n",
      "148 :  U.S. is headed for an economic recession.\n",
      "156 :  Alan\n",
      "157 :  Greenspan indicated on\n",
      "160 :  Monday that the\n",
      "163 :  U.S. economy would not sustain its recent growth, where the\n",
      "174 :  Dow\n",
      "175 :  Industrials set day-to-day records and the\n",
      "185 :  White\n",
      "186 :  House signaled on\n",
      "189 :  Tuesday that it would revise its estimate of fourth-quarter 2006 GDP growth down to an annual rate of about 2.3 percent from an initial forecast of 3.5 percent and was increasingly nervous that the figure could come in even lower.\n",
      "\n",
      "\n",
      "233 :  Around 3 p.m. EST,\n",
      "238 :  Reuters reported that the\n",
      "242 :  New\n",
      "243 :  York\n",
      "244 :  Stock\n",
      "245 :  Exchange had implemented on-floor tradition restrictions meant to curb the sell off.\n",
      "\n",
      "\n",
      "261 :  The decline also occurred on the day that a plot to assassinate\n",
      "273 :  U.S.\n",
      "274 :  Vice\n",
      "275 :  President\n",
      "276 :  Richard\n",
      "277 :  Cheney failed in\n",
      "280 :  Afghanistan.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.language import Language\n",
    "\n",
    "@Language.component(\"custom_sentencizer\")\n",
    "def custom_sentencizer(doc):\n",
    "    for tok in doc:\n",
    "        # Define sentence start if pipe + titlecase token\n",
    "        if doc[tok.i].is_title:\n",
    "            doc[tok.i].is_sent_start = True\n",
    "        else:\n",
    "            # Explicitly set sentence start to False otherwise, to tell\n",
    "            # the parser to leave those tokens alone\n",
    "            doc[tok.i].is_sent_start = False\n",
    "        # if tok.is_space:\n",
    "        #     doc[tok.i].is_sent_start = False\n",
    "    return doc\n",
    "\n",
    "text = \"\"\"\n",
    "\n",
    "The biggest U.S. stock market index, the Dow Jones, plunged by more than 416 points by the closing bell on Tuesday, the worst single-day decline since the re-opening of the markets following the September 11th terrorist attacks. The slip followed a 9% sell-off in Chinese markets. Other stock indices, such as the Nasdaq and the S&amp;P 500, dipped by 96 points and 50 points, respectively. It was the 7th largest single-day decline is U.S. history.\n",
    "\n",
    "Analysts blamed the slide on a number of factors: (1) U.S. and Chinese stock exchanges had powered upward for too long and were due for a significant correction; (2) inflation and the prices of bonds and equities had become too high; (3) the U.S. is headed for an economic recession. Alan Greenspan indicated on Monday that the U.S. economy would not sustain its recent growth, where the Dow Industrials set day-to-day records and the White House signaled on Tuesday that it would revise its estimate of fourth-quarter 2006 GDP growth down to an annual rate of about 2.3 percent from an initial forecast of 3.5 percent and was increasingly nervous that the figure could come in even lower.\n",
    "\n",
    "Around 3 p.m. EST, Reuters reported that the New York Stock Exchange had implemented on-floor tradition restrictions meant to curb the sell off.\n",
    "\n",
    "The decline also occurred on the day that a plot to assassinate U.S. Vice President Richard Cheney failed in Afghanistan.\n",
    "\n",
    "\"\"\"\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "nlp.add_pipe(\"custom_sentencizer\", before=\"parser\")  # Insert before the parser\n",
    "doc = nlp(text)\n",
    "for sent in doc.sents:\n",
    "    print(sent.start, \": \", sent.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"../text2graphs/tarsqi-dataset/myfile.txt\", \"x\")\n",
    "f.write(\"this is demo file\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20070810\n"
     ]
    }
   ],
   "source": [
    "value = \"2007-08-10T00:00:00\"\n",
    "value = value[0:10]\n",
    "value= value.replace('-','')\n",
    "print(value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/spacy/util.py:865: UserWarning: [W095] Model 'en_core_web_trf' (3.3.0) was trained with spaCy v3.3 and may not be 100% compatible with the current version (3.4.1). If you see errors or degraded performance, download a newer compatible model or retrain your custom model with the current spaCy version. For more details and available updates, run: python -m spacy validate\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jim Cramer head:  Cramer\n",
      "CNBC's Mad Money head:  Money\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/neo/environments/text2graphs/venv/lib/python3.8/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "text = \"\"\"Global stock markets fell today, in a mass sell-off stemming from the sub-prime mortgage crisis in the United States. The Dow Jones Industrial Average rebounded late in the day after falling more than 250 points, ending the day down about 31 points. The UK's FTSE-100 index fell 232.90 points to 6038.30, and Japan's Nikkei 225 fell 406.51 points to 16764.09. \n",
    "\n",
    "Central banks across the world are injecting funds into their banking systems to add liquidity, fearing that many financial firms with subprime ties will be insolvent. Yesterday, the U.S. Federal Reserve transferred US$24 billion to temporary reserves, following the European Central Bank, which authorized a record 83.6 billion addition to its banks, its biggest cash infusion ever. On Friday, the Fed entered into a $38 billion repurchase agreement of mortgage-backed securities, easing stockholder worries. Also on Friday, the Bank of Japan injected 1 trillion into Japan's financial system. \n",
    "\n",
    "The Federal Reserve met this week, but decided to maintain its target rate of 5.25%, although on Friday the federal funds rate was hovering around 6%, indicating a drop in liquidity. \n",
    "\n",
    "The volatile week began last Friday with Bear Stearns tumbling as a result from its complete loss of two major hedge funds worth more than $1.5 billion. The hedge funds had been dangerously exposed to the massive sub-prime mortgage failure, and the company announced it was unable to return any money to investors. \n",
    "\n",
    "Washington Mutual, and Countrywide Financial, both very large U.S. home loan lenders, saw shares fall. Countrywide Financial made a statement this week, saying they will be forced to retain a greater proportion of mortgage. American Home Mortgage Investment Corp, another large lender, recently filed for bankruptcy. The U.S. housing market has been declining for more than two years after the Federal Reserve raised interest rates 17 times. Now, lenders are in a quagmire from millions of people who are unable to repay loans after taking adjustable rate mortgages, teaser rates, interest-only mortgages, or piggyback rates. \n",
    "\n",
    "Jim Cramer, of CNBC's Mad Money, remarked that as many as seven million people will lose their homes from bad mortgages. Last Friday, Cramer went on a tirade on CNBC's Street Signs, saying that the \"Fed was asleep\" and called for them to lower rates immediately. \n",
    "\n",
    "Asian and European markets have become increasingly entangled in the subprime mortgage crisis in the U.S. Deutsche Bank of Germany lost almost $3.5 billion in share value, forcing the government to organize a bail-out. France's largest bank, BNP Paribas SA, halted withdrawals from three large investment funds which were crippled by sub-prime exposure.\n",
    "\"\"\"\n",
    "\n",
    "text2 = \"\"\"Jim Cramer, of CNBC's Mad Money\"\"\"\n",
    "doc = nlp(text2)\n",
    "\n",
    "for chunk in doc.noun_chunks:\n",
    "    print(chunk.text, \"head: \", chunk.root.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proofpoint Organization\n",
      "DroidJack RAT Malware\n",
      "Android System\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"../corpus/output/model-best\")\n",
    "doc = nlp(\"Proofpoint report mentions that the German-language messages were turned off once the UK messages were established, indicating a conscious effort to spread FluBot 446833e3f8b04d4c3c2d2288e456328266524e396adbfeba3769d00727481e80 and DroidJack RAT in Android phones.\")\n",
    "#print(doc.ents)\n",
    "\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6256d0f4a06255e31270570e134280c34365148f596144dcc11c3e5a968e9226"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
